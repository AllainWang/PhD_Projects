{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1,\n",
       "       3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "       1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "       3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3,\n",
       "       2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3,\n",
       "       3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2,\n",
       "       3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3,\n",
       "       2, 1, 3, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 3,\n",
       "       3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1,\n",
       "       3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3,\n",
       "       3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1,\n",
       "       3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1,\n",
       "       3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas\n",
    "import scipy.special\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "def tri_data(numbers):\n",
    "    tri_data = np.zeros(numbers, dtype=np.int8)\n",
    "    tri_data[np.arange(5)] = np.random.choice(np.arange(1,4), 5)\n",
    "    #tri_data[np.arange(3)] = [1, 2, 3]\n",
    "    for n in np.arange(5, numbers):\n",
    "        if tri_data[n-3] == 1:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.99, 0.005, 0.005))\n",
    "        if tri_data[n-3] == 2:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.005, 0.99, 0.005))\n",
    "        if tri_data[n-3] == 3:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.005, 0.005, 0.99))\n",
    "    return(tri_data)\n",
    "data_all = tri_data(700)\n",
    "data = data_all[np.arange(200)]\n",
    "data_all\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 2, 1, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1,\n",
       "       2, 2, 3, 2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3,\n",
       "       2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3,\n",
       "       2, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 3,\n",
       "       3, 3, 3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3,\n",
       "       3, 3, 1, 1, 1, 3, 2, 1, 1, 2, 2, 3, 1, 1, 3, 3, 2, 1, 3, 3, 3, 1, 2,\n",
       "       2, 3, 1, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 3, 3, 1, 3, 3, 2, 3, 2, 2, 2,\n",
       "       3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 2, 2, 1, 3, 3,\n",
       "       2, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 2, 2, 1, 3, 3, 1, 1, 3, 3, 2, 2, 3,\n",
       "       2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3,\n",
       "       3, 2, 2, 1, 1, 1, 2, 3, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3,\n",
       "       2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
       "       3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 1, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 2, 3, 1, 2, 2,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 3, 1, 1, 2, 2, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       1, 3, 3, 3, 1, 1, 2, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 2, 2, 3, 3, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 3, 2, 2, 2, 1, 2, 2, 2, 1, 3, 1, 2, 2, 3, 2, 2, 2, 3, 2, 2, 1, 3,\n",
       "       2, 2, 1, 3, 1, 3, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 1, 3, 3, 1, 3, 3, 3,\n",
       "       2, 2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 3, 2, 2, 1,\n",
       "       3, 3, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 2,\n",
       "       3, 3, 3, 2, 1, 1, 1, 3, 1, 1, 1, 2, 3, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 3, 3, 2, 1, 3, 1, 1, 2, 2, 3, 3, 2, 3, 3, 1, 1, 2, 1, 1, 2,\n",
       "       2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 2, 1, 3,\n",
       "       2, 3, 3, 1, 2, 3, 1, 1, 3, 3, 3, 3, 1, 2, 3, 3, 2, 1, 2, 2, 2, 3, 3,\n",
       "       2, 2, 1, 1, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 2, 2, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 1, 3, 2, 1,\n",
       "       1, 2, 1, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 1, 3, 2, 1, 2,\n",
       "       2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 2, 1, 1, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 2, 2, 3, 1, 1, 2, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2,\n",
       "       2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1,\n",
       "       1, 2, 2, 3, 1, 3, 3, 2, 1, 2, 2, 3, 2, 2, 3, 2, 2, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 3, 1, 1, 1, 3, 2, 3, 3, 1, 1, 3, 1, 1, 3, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 1, 3, 3, 2, 1, 3, 3, 2, 3, 3, 1, 1,\n",
       "       2, 2, 1, 2, 2, 3, 1, 3, 3, 2, 1, 2, 2, 3, 3, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 3, 3, 1, 3, 3, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 1, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 3, 3, 1, 1, 2, 3, 3, 2, 1, 2, 2, 3, 2, 2, 1, 2, 2, 1, 1, 3, 2,\n",
       "       2, 1, 3, 1, 1, 3, 3, 1, 3, 3, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 2, 2, 1, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 1,\n",
       "       1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 3, 2, 2, 1, 2, 2, 1, 3, 1, 1, 1, 3,\n",
       "       3, 2, 1, 1, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 1, 1, 3, 3, 1, 1, 3, 2, 1,\n",
       "       1, 2, 2, 3, 2, 2, 1, 1, 3, 1, 3, 3, 3, 2, 2, 1, 3, 3, 1, 3, 3, 1, 2,\n",
       "       3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 1,\n",
       "       1, 3, 1, 1, 3, 3, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2, 1, 3, 2, 1,\n",
       "       3, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 1, 1, 3, 2, 1, 3, 1, 1, 2,\n",
       "       2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 2, 1, 1, 2,\n",
       "       2, 3, 3, 1, 3, 3, 1, 2, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tri_data(numbers):\n",
    "    tri_data = np.zeros(numbers, dtype=np.int8)\n",
    "    tri_data[np.arange(5)] = np.random.choice(np.arange(1,4), 5)\n",
    "    #tri_data[np.arange(3)] = [1, 2, 3]\n",
    "    for n in np.arange(5, numbers):\n",
    "        if tri_data[n-3] == 1 and tri_data[n-1] == 1:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.9, 0.05, 0.05))\n",
    "        elif tri_data[n-3] == 2 and tri_data[n-1] == 2:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.05, 0.9, 0.05))\n",
    "        elif tri_data[n-3] == 3 and tri_data[n-1] == 3:\n",
    "            tri_data[n] = np.random.choice(np.arange(1,4), p = (0.05, 0.05, 0.9))\n",
    "        else: tri_data[n] = np.random.choice(np.arange(1,4))\n",
    "  \n",
    "    return(tri_data)\n",
    "data_all = tri_data(700)\n",
    "data = data_all[np.arange(200)]\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Allain/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:47: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:79: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:107: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:111: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:115: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:119: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:123: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:131: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:138: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:140: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:141: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:144: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:146: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:147: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:150: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:152: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:153: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:156: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:158: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:159: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:162: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:164: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:165: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:197: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:201: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:207: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:211: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:217: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:221: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:227: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:231: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:237: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:241: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:292: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:320: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:324: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:328: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:332: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:336: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:376: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:378: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:379: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:382: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:384: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:385: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:388: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:390: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:391: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:394: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:396: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:397: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:400: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:402: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:403: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:435: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:439: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:445: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:449: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:455: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:459: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:465: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:469: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:475: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:479: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:346: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:367: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:55:31.394614\n"
     ]
    }
   ],
   "source": [
    "#start_time = datetime.now()\n",
    "S = 20000\n",
    "burnin = S*0.8\n",
    "L = 100\n",
    "alpha0 = 1\n",
    "\n",
    "# generate z1t, z2t, z3t... according to the corresponding k1, k2, k3, ...\n",
    "k1 = np.zeros(S)\n",
    "k2 = np.zeros(S)\n",
    "k3 = np.zeros(S)\n",
    "k4 = np.zeros(S)\n",
    "k5 = np.zeros(S)\n",
    "k1[0] = 2\n",
    "k2[0] = 2\n",
    "k3[0] = 2\n",
    "k4[0] = 2\n",
    "k5[0] = 2\n",
    "z_j_t = np.zeros((5, len(data), S))\n",
    "z_j_t[:,:,0] = 1\n",
    "C0 = 3\n",
    "alpha = 1/C0\n",
    "q = 5\n",
    "eta = 0.5\n",
    "gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = 1/C0\n",
    "\n",
    "#step 1\n",
    "#define pi_ast_l\n",
    "pi_ast_l = np.zeros(L)\n",
    "V_l = np.random.beta(1, alpha0, L)\n",
    "pi_ast_l[0] = V_l[0]\n",
    "oneminusV_l = 1 - V_l \n",
    "for n in np.arange(1, L):\n",
    "    pi_ast_l[n] = V_l[n]*np.prod(oneminusV_l[:n])   \n",
    "    \n",
    "lambda_ast_l = np.random.dirichlet(np.repeat(1/C0, C0), L)\n",
    "\n",
    "def nh1h2h3h4h5y(h1, h2, h3, h4, h5, y):\n",
    "    case1 = (z_j_t[0, q:, 0] == h1)*1\n",
    "    case2 = (z_j_t[1, q:, 0] == h2)*1 \n",
    "    case3 = (z_j_t[2, q:, 0] == h3)*1\n",
    "    case4 = (z_j_t[3, q:, 0] == h4)*1\n",
    "    case5 = (z_j_t[4, q:, 0] == h5)*1\n",
    "    case12345 = case1*case2*case3*case4*case5\n",
    "    casey = (data[q:] == y)*1\n",
    "    nh1h2h3h4h5y = np.sum(case12345*casey)\n",
    "    return(nh1h2h3h4h5y)\n",
    "\n",
    "#simulating l, PLN()[l-1] means the prob of l with h1, h2, h3\n",
    "def PLN(h1, h2, h3, h4, h5):\n",
    "    lamny = [(lambda_ast_l[:, y-1]**nh1h2h3h4h5y(h1, h2, h3, h4, h5, y)) for y in range(1, C0+1)]\n",
    "    PLNnotnorm = pi_ast_l*np.prod(lamny, axis = 0)\n",
    "    PLN = PLNnotnorm/np.sum(PLNnotnorm)\n",
    "    return PLN\n",
    "\n",
    "def sample_z_ast(h1, h2, h3, h4, h5):\n",
    "    z = np.random.choice(np.arange(1, L+1), p = PLN(h1, h2, h3, h4, h5))\n",
    "    return z\n",
    "h1 = np.arange(1, k1[0]+1)\n",
    "h2 = np.arange(1, k2[0]+1)\n",
    "h3 = np.arange(1, k3[0]+1)\n",
    "h4 = np.arange(1, k4[0]+1)\n",
    "h5 = np.arange(1, k5[0]+1)\n",
    "per = list(itertools.product(h1, h2, h3, h4, h5)) #permutations\n",
    "zz = list(map(lambda x: sample_z_ast(*x), per))\n",
    "z_ast_h1h2h3h4h5 = np.reshape(zz, (k1[0],k2[0],k3[0],k4[0],k5[0]))\n",
    "\n",
    "#step 2\n",
    "def sample_V_l(l): \n",
    "    return np.random.beta(1 + np.count_nonzero(z_ast_h1h2h3h4h5 == l), alpha0 + np.count_nonzero(z_ast_h1h2h3h4h5 > l), 1).tolist()\n",
    "V_l = np.concatenate(list(map(lambda x: sample_V_l(x), range(1, L+1))))\n",
    "pi_ast_l[0] = V_l[0]\n",
    "oneminusV_l = 1 - V_l \n",
    "for n in np.arange(1, L):\n",
    "    pi_ast_l[n] = V_l[n]*np.prod(oneminusV_l[:n])\n",
    "\n",
    "#step 3\n",
    "def n_ast_l_y(l, y):\n",
    "    def nnn(h1, h2, h3, h4, h5):\n",
    "        nnn = np.count_nonzero(z_ast_h1h2h3h4h5[h1-1, h2-1, h3-1, h4-1, h5-1] == l)*nh1h2h3h4h5y(h1, h2, h3, h4, h5, y)\n",
    "        return nnn\n",
    "    h1 = np.arange(1, k1[0]+1)\n",
    "    h2 = np.arange(1, k2[0]+1)\n",
    "    h3 = np.arange(1, k3[0]+1)\n",
    "    h4 = np.arange(1, k4[0]+1)\n",
    "    h5 = np.arange(1, k5[0]+1)\n",
    "    per = list(itertools.product(h1, h2, h3, h4, h5))\n",
    "    nn = list(map(lambda x: nnn(*x), per))\n",
    "    #return per\n",
    "    n_ast_l_y = np.sum(nn)\n",
    "    return(n_ast_l_y)\n",
    "\n",
    "#lambda_ast_l[l-1, y-1] means the value of (l,y)\n",
    "def nrd(l):\n",
    "    nrd = np.random.dirichlet([1/C0 + n_ast_l_y(l, y) for y in np.arange(1, C0+1)])\n",
    "    return nrd\n",
    "lambda_ast_l = np.array(list(map(lambda x: nrd(x), np.arange(1, L+1))))\n",
    "\n",
    "\n",
    "#step 4\n",
    "def n_j_wj_hj(j, wj, hj):\n",
    "    case1 = (z_j_t[j-1, np.arange(q, len(data)),0] == hj)*1\n",
    "    case2 = (data[np.arange(q, len(data))-j] == wj)*1\n",
    "    n_j_wj_hj = np.sum(case1*case2)\n",
    "    return(n_j_wj_hj)\n",
    "\n",
    "\n",
    "pi_1_w1 = np.zeros((C0, k1[0]))\n",
    "for c in np.arange(C0):\n",
    "        pi_1_w1[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(1, c+1, h1) for h1 in np.arange(1, k1[0]+1)])\n",
    "        \n",
    "pi_2_w2 = np.zeros((C0, k2[0]))\n",
    "for c in np.arange(C0):\n",
    "        pi_2_w2[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(2, c+1, h2) for h2 in np.arange(1, k2[0]+1)])\n",
    "        \n",
    "pi_3_w3 = np.zeros((C0, k3[0]))\n",
    "for c in np.arange(C0):\n",
    "        pi_3_w3[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(3, c+1, h3) for h3 in np.arange(1, k3[0]+1)])\n",
    "\n",
    "pi_4_w4 = np.zeros((C0, k4[0]))\n",
    "for c in np.arange(C0):\n",
    "        pi_4_w4[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(4, c+1, h4) for h4 in np.arange(1, k4[0]+1)])\n",
    "        \n",
    "pi_5_w5 = np.zeros((C0, k5[0]))\n",
    "for c in np.arange(C0):\n",
    "        pi_5_w5[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(5, c+1, h5) for h5 in np.arange(1, k5[0]+1)])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "##prob density of y_pred\n",
    "rec_pred_y_den = np.zeros((C0, C0, C0, C0, C0, C0, S-burnin-1))\n",
    "\n",
    "\n",
    "\n",
    "#step 5\n",
    "t = np.arange(q, len(data))\n",
    "\n",
    "PWLZY_1 = np.zeros((k1[0], len(data)))\n",
    "for h in np.arange(k1[0]):\n",
    "    PWLZY_1[h,t] = pi_1_w1[data[t-1]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[h, np.array(z_j_t[1,t,0], dtype = np.int8)-1, \n",
    "                   np.array(z_j_t[2,t,0], dtype = np.int8)-1, np.array(z_j_t[3,t,0], dtype = np.int8)-1, np.array(z_j_t[4,t,0], dtype = np.int8)-1]-1, data[t]-1]\n",
    "PWLZY_1[:,t] = PWLZY_1[:,t]/np.sum(PWLZY_1[:,t], axis = 0)\n",
    "        \n",
    "PWLZY_2 = np.zeros((k2[0], len(data)))\n",
    "for h in np.arange(k2[0]):\n",
    "    PWLZY_2[h,t] = pi_2_w2[data[t-2]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,0], dtype = np.int8)-1, h, \n",
    "                   np.array(z_j_t[2,t,0], dtype = np.int8)-1, np.array(z_j_t[3,t,0], dtype = np.int8)-1, np.array(z_j_t[4,t,0], dtype = np.int8)-1]-1, data[t]-1]\n",
    "PWLZY_2[:,t] = PWLZY_2[:,t]/np.sum(PWLZY_2[:,t], axis = 0)\n",
    "        \n",
    "PWLZY_3 = np.zeros((k3[0], len(data)))\n",
    "for h in np.arange(k3[0]):\n",
    "    PWLZY_3[h,t] = pi_3_w3[data[t-3]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,0], dtype = np.int8)-1, \n",
    "                   np.array(z_j_t[1,t,0], dtype = np.int8)-1, h, np.array(z_j_t[3,t,0], dtype = np.int8)-1, np.array(z_j_t[4,t,0], dtype = np.int8)-1]-1, data[t]-1]\n",
    "PWLZY_3[:,t] = PWLZY_3[:,t]/np.sum(PWLZY_3[:,t], axis = 0)\n",
    "\n",
    "PWLZY_4 = np.zeros((k4[0], len(data)))\n",
    "for h in np.arange(k4[0]):\n",
    "    PWLZY_4[h,t] = pi_4_w4[data[t-4]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,0], dtype = np.int8)-1, \n",
    "                   np.array(z_j_t[1,t,0], dtype = np.int8)-1, np.array(z_j_t[2,t,0], dtype = np.int8)-1, h, np.array(z_j_t[4,t,0], dtype = np.int8)-1]-1, data[t]-1]\n",
    "PWLZY_4[:,t] = PWLZY_4[:,t]/np.sum(PWLZY_4[:,t], axis = 0)\n",
    "\n",
    "PWLZY_5 = np.zeros((k5[0], len(data)))\n",
    "for h in np.arange(k5[0]):\n",
    "    PWLZY_5[h,t] = pi_5_w5[data[t-5]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,0], dtype = np.int8)-1, \n",
    "                   np.array(z_j_t[1,t,0], dtype = np.int8)-1, np.array(z_j_t[2,t,0], dtype = np.int8)-1, np.array(z_j_t[3,t,0], dtype = np.int8)-1, h]-1, data[t]-1]\n",
    "PWLZY_5[:,t] = PWLZY_5[:,t]/np.sum(PWLZY_5[:,t], axis = 0)\n",
    "\n",
    "pp1 = PWLZY_1[:,np.arange(q, len(data))].transpose()\n",
    "c1 = pp1.cumsum(axis=1)\n",
    "u1 = np.random.rand(len(c1), 1)\n",
    "z_j_t[0,q:,1] = (u1 < c1).argmax(axis=1)+1\n",
    "\n",
    "pp2 = PWLZY_2[:,np.arange(q, len(data))].transpose()\n",
    "c2 = pp2.cumsum(axis=1)\n",
    "u2 = np.random.rand(len(c2), 1)\n",
    "z_j_t[1,q:,1] = (u2 < c2).argmax(axis=1)+1\n",
    "\n",
    "pp3 = PWLZY_3[:,np.arange(q, len(data))].transpose()\n",
    "c3 = pp3.cumsum(axis=1)\n",
    "u3 = np.random.rand(len(c3), 1)\n",
    "z_j_t[2,q:,1] = (u3 < c3).argmax(axis=1)+1\n",
    "\n",
    "pp4 = PWLZY_4[:,np.arange(q, len(data))].transpose()\n",
    "c4 = pp4.cumsum(axis=1)\n",
    "u4 = np.random.rand(len(c4), 1)\n",
    "z_j_t[3,q:,1] = (u4 < c4).argmax(axis=1)+1\n",
    "\n",
    "pp5 = PWLZY_5[:,np.arange(q, len(data))].transpose()\n",
    "c5 = pp5.cumsum(axis=1)\n",
    "u5 = np.random.rand(len(c5), 1)\n",
    "z_j_t[4,q:,1] = (u5 < c5).argmax(axis=1)+1\n",
    "\n",
    "#step 6\n",
    "log_p_k1 = np.zeros(C0)\n",
    "for i in np.arange(max(z_j_t[0, :, 1])-1, C0):\n",
    "    log_p_k1[i] = -eta*1*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma1) - scipy.special.gammaln((i+1)*gamma1 + \n",
    "              list(data[(q-1):(len(data)-1)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "log_p_k1_new = log_p_k1[log_p_k1 != 0] - np.max(log_p_k1[log_p_k1 != 0])\n",
    "act_p_k1 = np.exp(log_p_k1_new)\n",
    "act_p1 = act_p_k1/np.sum(act_p_k1)\n",
    "p1 = np.append(np.zeros(max(z_j_t[0, :, 1])-1), act_p1)\n",
    "k1[1] = np.random.choice(np.arange(1, C0+1), p = p1)\n",
    "\n",
    "log_p_k2 = np.zeros(C0)\n",
    "for i in np.arange(max(z_j_t[1, :, 1])-1, C0):\n",
    "    log_p_k2[i] = -eta*2*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma2) - scipy.special.gammaln((i+1)*gamma2 + \n",
    "              list(data[(q-2):(len(data)-2)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "log_p_k2_new = log_p_k2[log_p_k2 != 0] - np.max(log_p_k2[log_p_k2 != 0])\n",
    "act_p_k2 = np.exp(log_p_k2_new)\n",
    "act_p2 = act_p_k2/np.sum(act_p_k2)\n",
    "p2 = np.append(np.zeros(max(z_j_t[1, :, 1])-1), act_p2)\n",
    "k2[1] = np.random.choice(np.arange(1, C0+1), p = p2)\n",
    "\n",
    "log_p_k3 = np.zeros(C0)\n",
    "for i in np.arange(max(z_j_t[2, :, 1])-1, C0):\n",
    "    log_p_k3[i] = -eta*3*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma3) - scipy.special.gammaln((i+1)*gamma3 + \n",
    "              list(data[(q-3):(len(data)-3)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "log_p_k3_new = log_p_k3[log_p_k3 != 0] - np.max(log_p_k3[log_p_k3 != 0])\n",
    "act_p_k3 = np.exp(log_p_k3_new)\n",
    "act_p3 = act_p_k3/np.sum(act_p_k3)\n",
    "p3 = np.append(np.zeros(max(z_j_t[2, :, 1])-1), act_p3)\n",
    "k3[1] = np.random.choice(range(1, C0+1), p = p3)\n",
    "\n",
    "log_p_k4 = np.zeros(C0)\n",
    "for i in np.arange(max(z_j_t[3, :, 1])-1, C0):\n",
    "    log_p_k4[i] = -eta*4*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma4) - scipy.special.gammaln((i+1)*gamma4 + \n",
    "              list(data[(q-4):(len(data)-4)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "log_p_k4_new = log_p_k4[log_p_k4 != 0] - np.max(log_p_k4[log_p_k4 != 0])\n",
    "act_p_k4 = np.exp(log_p_k4_new)\n",
    "act_p4 = act_p_k4/np.sum(act_p_k4)\n",
    "p4 = np.append(np.zeros(max(z_j_t[3, :, 1])-1), act_p4)\n",
    "k4[1] = np.random.choice(range(1, C0+1), p = p4)\n",
    "\n",
    "log_p_k5 = np.zeros(C0)\n",
    "for i in np.arange(max(z_j_t[4, :, 1])-1, C0):\n",
    "    log_p_k5[i] = -eta*5*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma5) - scipy.special.gammaln((i+1)*gamma5 + \n",
    "              list(data[(q-5):(len(data)-5)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "log_p_k5_new = log_p_k5[log_p_k5 != 0] - np.max(log_p_k5[log_p_k5 != 0])\n",
    "act_p_k5 = np.exp(log_p_k5_new)\n",
    "act_p5 = act_p_k5/np.sum(act_p_k5)\n",
    "p5 = np.append(np.zeros(max(z_j_t[4, :, 1])-1), act_p5)\n",
    "k5[1] = np.random.choice(range(1, C0+1), p = p5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "for s in np.arange(1, S-1):\n",
    "#step 1\n",
    "    def nh1h2h3h4h5y(h1, h2, h3, h4, h5, y):\n",
    "        case1 = (z_j_t[0, q:, s] == h1)*1\n",
    "        case2 = (z_j_t[1, q:, s] == h2)*1 \n",
    "        case3 = (z_j_t[2, q:, s] == h3)*1\n",
    "        case4 = (z_j_t[3, q:, s] == h4)*1\n",
    "        case5 = (z_j_t[4, q:, s] == h5)*1\n",
    "        case12345 = case1*case2*case3*case4*case5\n",
    "        casey = (data[q:] == y)*1\n",
    "        nh1h2h3h4h5y = np.sum(case12345*casey)\n",
    "        return(nh1h2h3h4h5y)\n",
    "\n",
    "#simulating l, PLN()[l-1] means the prob of l with h1, h2, h3\n",
    "    def PLN(h1, h2, h3, h4, h5):\n",
    "        lamny = [(lambda_ast_l[:, y-1]**nh1h2h3h4h5y(h1, h2, h3, h4, h5, y)) for y in range(1, C0+1)]\n",
    "        PLNnotnorm = pi_ast_l*np.prod(lamny, axis = 0)\n",
    "        PLN = PLNnotnorm/np.sum(PLNnotnorm)\n",
    "        return PLN\n",
    "\n",
    "    def sample_z_ast(h1, h2, h3, h4, h5):\n",
    "        z = np.random.choice(np.arange(1, L+1), p = PLN(h1, h2, h3, h4, h5))\n",
    "        return z\n",
    "    h1 = np.arange(1, k1[s]+1)\n",
    "    h2 = np.arange(1, k2[s]+1)\n",
    "    h3 = np.arange(1, k3[s]+1)\n",
    "    h4 = np.arange(1, k4[s]+1)\n",
    "    h5 = np.arange(1, k5[s]+1)\n",
    "    per = list(itertools.product(h1, h2, h3, h4, h5)) #permutations\n",
    "    zz = list(map(lambda x: sample_z_ast(*x), per))\n",
    "    z_ast_h1h2h3h4h5 = np.reshape(zz, (k1[s],k2[s],k3[s],k4[s],k5[s]))\n",
    "    \n",
    "#step 2\n",
    "    def sample_V_l(l): \n",
    "        return np.random.beta(1 + np.count_nonzero(z_ast_h1h2h3h4h5 == l), alpha0 + np.count_nonzero(z_ast_h1h2h3h4h5 > l), 1).tolist()\n",
    "    V_l = np.concatenate(list(map(lambda x: sample_V_l(x), range(1, L+1))))\n",
    "    pi_ast_l[0] = V_l[0]\n",
    "    oneminusV_l = 1 - V_l \n",
    "    for n in np.arange(1, L):\n",
    "        pi_ast_l[n] = V_l[n]*np.prod(oneminusV_l[:n])\n",
    "        \n",
    "#step 3\n",
    "    def n_ast_l_y(l, y):\n",
    "        def nnn(h1, h2, h3, h4, h5):\n",
    "            nnn = np.count_nonzero(z_ast_h1h2h3h4h5[h1-1, h2-1, h3-1, h4-1, h5-1] == l)*nh1h2h3h4h5y(h1, h2, h3, h4, h5, y)\n",
    "            return nnn\n",
    "        h1 = np.arange(1, k1[s]+1)\n",
    "        h2 = np.arange(1, k2[s]+1)\n",
    "        h3 = np.arange(1, k3[s]+1)\n",
    "        h4 = np.arange(1, k4[s]+1)\n",
    "        h5 = np.arange(1, k5[s]+1)\n",
    "        per = list(itertools.product(h1, h2, h3, h4, h5))\n",
    "        nn = list(map(lambda x: nnn(*x), per))\n",
    "        #return per\n",
    "        n_ast_l_y = np.sum(nn)\n",
    "        return(n_ast_l_y)\n",
    "\n",
    "#lambda_ast_l[l-1, y-1] means the value of (l,y)\n",
    "    def nrd(l):\n",
    "        nrd = np.random.dirichlet([1/C0 + n_ast_l_y(l, y) for y in np.arange(1, C0+1)])\n",
    "        return nrd\n",
    "    lambda_ast_l = np.array(list(map(lambda x: nrd(x), np.arange(1, L+1))))\n",
    "    \n",
    "    \n",
    "#step 4\n",
    "    def n_j_wj_hj(j, wj, hj):\n",
    "        case1 = (z_j_t[j-1, np.arange(q, len(data)),s] == hj)*1\n",
    "        case2 = (data[np.arange(q, len(data))-j] == wj)*1\n",
    "        n_j_wj_hj = np.sum(case1*case2)\n",
    "        return(n_j_wj_hj)\n",
    "\n",
    "\n",
    "    pi_1_w1 = np.zeros((C0, k1[s]))\n",
    "    for c in np.arange(C0):\n",
    "            pi_1_w1[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(1, c+1, h1) for h1 in np.arange(1, k1[s]+1)])\n",
    "        \n",
    "    pi_2_w2 = np.zeros((C0, k2[s]))\n",
    "    for c in np.arange(C0):\n",
    "            pi_2_w2[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(2, c+1, h2) for h2 in np.arange(1, k2[s]+1)])\n",
    "        \n",
    "    pi_3_w3 = np.zeros((C0, k3[s]))\n",
    "    for c in np.arange(C0):\n",
    "            pi_3_w3[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(3, c+1, h3) for h3 in np.arange(1, k3[s]+1)])\n",
    "\n",
    "    pi_4_w4 = np.zeros((C0, k4[s]))\n",
    "    for c in np.arange(C0):\n",
    "            pi_4_w4[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(4, c+1, h4) for h4 in np.arange(1, k4[s]+1)])\n",
    "        \n",
    "    pi_5_w5 = np.zeros((C0, k5[s]))\n",
    "    for c in np.arange(C0):\n",
    "            pi_5_w5[c, :] = np.random.dirichlet([1/C0 + n_j_wj_hj(5, c+1, h5) for h5 in np.arange(1, k5[s]+1)])\n",
    "            \n",
    "            \n",
    "    ##prob density of y_pred\n",
    "    if s >= burnin:\n",
    "        def pred_y_density(yt_1, yt_2, yt_3, yt_4, yt_5):\n",
    "            \n",
    "            def tensor_y(h1, h2, h3, h4, h5):\n",
    "                return lambda_ast_l[z_ast_h1h2h3h4h5[h1,h2,h3,h4,h5]-1,:]*pi_1_w1[yt_1-1, h1]*pi_2_w2[yt_2-1, h2]*pi_3_w3[yt_3-1, h3]*pi_4_w4[yt_4-1, h4]*pi_5_w5[yt_5-1, h5]\n",
    "        \n",
    "            \n",
    "            h_1 = np.arange(k1[s])\n",
    "            h_2 = np.arange(k2[s])\n",
    "            h_3 = np.arange(k3[s])\n",
    "            h_4 = np.arange(k4[s])\n",
    "            h_5 = np.arange(k5[s])\n",
    "            per_h = list(itertools.product(h_1, h_2, h_3, h_4, h_5))\n",
    "            ten_y = list(map(lambda x: tensor_y(*x), per_h))\n",
    "            return np.sum(ten_y, axis = 0)\n",
    "\n",
    "\n",
    "        y_1 = np.arange(1, C0+1)\n",
    "        y_2 = np.arange(1, C0+1)\n",
    "        y_3 = np.arange(1, C0+1)\n",
    "        y_4 = np.arange(1, C0+1)\n",
    "        y_5 = np.arange(1, C0+1)\n",
    "        per_y = list(itertools.product(y_1, y_2, y_3, y_4, y_5)) #permutations\n",
    "        pred_y = list(map(lambda x: pred_y_density(*x), per_y))\n",
    "        pred_y_den = np.reshape(pred_y, (C0,C0,C0,C0,C0,C0))\n",
    "        rec_pred_y_den[:,:,:,:,:,:,s-burnin] = pred_y_den\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#step 5\n",
    "    t = np.arange(q, len(data))\n",
    "\n",
    "    PWLZY_1 = np.zeros((k1[s], len(data)))\n",
    "    for h in np.arange(k1[s]):\n",
    "        PWLZY_1[h,t] = pi_1_w1[data[t-1]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[h, np.array(z_j_t[1,t,s], dtype = np.int8)-1, \n",
    "                       np.array(z_j_t[2,t,s], dtype = np.int8)-1, np.array(z_j_t[3,t,s], dtype = np.int8)-1, np.array(z_j_t[4,t,s], dtype = np.int8)-1]-1, data[t]-1]\n",
    "    PWLZY_1[:,t] = PWLZY_1[:,t]/np.sum(PWLZY_1[:,t], axis = 0)\n",
    "        \n",
    "    PWLZY_2 = np.zeros((k2[s], len(data)))\n",
    "    for h in np.arange(k2[s]):\n",
    "        PWLZY_2[h,t] = pi_2_w2[data[t-2]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,s], dtype = np.int8)-1, h, \n",
    "                       np.array(z_j_t[2,t,s], dtype = np.int8)-1, np.array(z_j_t[3,t,s], dtype = np.int8)-1, np.array(z_j_t[4,t,s], dtype = np.int8)-1]-1, data[t]-1]\n",
    "    PWLZY_2[:,t] = PWLZY_2[:,t]/np.sum(PWLZY_2[:,t], axis = 0)\n",
    "        \n",
    "    PWLZY_3 = np.zeros((k3[s], len(data)))\n",
    "    for h in np.arange(k3[s]):\n",
    "        PWLZY_3[h,t] = pi_3_w3[data[t-3]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,s], dtype = np.int8)-1, \n",
    "                       np.array(z_j_t[1,t,s], dtype = np.int8)-1, h, np.array(z_j_t[3,t,s], dtype = np.int8)-1, np.array(z_j_t[4,t,s], dtype = np.int8)-1]-1, data[t]-1]\n",
    "    PWLZY_3[:,t] = PWLZY_3[:,t]/np.sum(PWLZY_3[:,t], axis = 0)\n",
    "\n",
    "    PWLZY_4 = np.zeros((k4[s], len(data)))\n",
    "    for h in np.arange(k4[s]):\n",
    "        PWLZY_4[h,t] = pi_4_w4[data[t-4]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,s], dtype = np.int8)-1, \n",
    "                       np.array(z_j_t[1,t,s], dtype = np.int8)-1, np.array(z_j_t[2,t,s], dtype = np.int8)-1, h, np.array(z_j_t[4,t,s], dtype = np.int8)-1]-1, data[t]-1]\n",
    "    PWLZY_4[:,t] = PWLZY_4[:,t]/np.sum(PWLZY_4[:,t], axis = 0)\n",
    "\n",
    "    PWLZY_5 = np.zeros((k5[s], len(data)))\n",
    "    for h in np.arange(k5[s]):\n",
    "        PWLZY_5[h,t] = pi_5_w5[data[t-5]-1, h]*lambda_ast_l[z_ast_h1h2h3h4h5[np.array(z_j_t[0,t,s], dtype = np.int8)-1, \n",
    "                       np.array(z_j_t[1,t,s], dtype = np.int8)-1, np.array(z_j_t[2,t,s], dtype = np.int8)-1, np.array(z_j_t[3,t,s], dtype = np.int8)-1, h]-1, data[t]-1]\n",
    "    PWLZY_5[:,t] = PWLZY_5[:,t]/np.sum(PWLZY_5[:,t], axis = 0)\n",
    "\n",
    "    pp1 = PWLZY_1[:,np.arange(q, len(data))].transpose()\n",
    "    c1 = pp1.cumsum(axis=1)\n",
    "    u1 = np.random.rand(len(c1), 1)\n",
    "    z_j_t[0,q:,s+1] = (u1 < c1).argmax(axis=1)+1\n",
    "\n",
    "    pp2 = PWLZY_2[:,np.arange(q, len(data))].transpose()\n",
    "    c2 = pp2.cumsum(axis=1)\n",
    "    u2 = np.random.rand(len(c2), 1)\n",
    "    z_j_t[1,q:,s+1] = (u2 < c2).argmax(axis=1)+1\n",
    "\n",
    "    pp3 = PWLZY_3[:,np.arange(q, len(data))].transpose()\n",
    "    c3 = pp3.cumsum(axis=1)\n",
    "    u3 = np.random.rand(len(c3), 1)\n",
    "    z_j_t[2,q:,s+1] = (u3 < c3).argmax(axis=1)+1\n",
    "\n",
    "    pp4 = PWLZY_4[:,np.arange(q, len(data))].transpose()\n",
    "    c4 = pp4.cumsum(axis=1)\n",
    "    u4 = np.random.rand(len(c4), 1)\n",
    "    z_j_t[3,q:,s+1] = (u4 < c4).argmax(axis=1)+1\n",
    "\n",
    "    pp5 = PWLZY_5[:,np.arange(q, len(data))].transpose()\n",
    "    c5 = pp5.cumsum(axis=1)\n",
    "    u5 = np.random.rand(len(c5), 1)\n",
    "    z_j_t[4,q:,s+1] = (u5 < c5).argmax(axis=1)+1\n",
    "    \n",
    "    #step 6\n",
    "    log_p_k1 = np.zeros(C0)\n",
    "    for i in np.arange(max(z_j_t[0, :, s+1])-1, C0):\n",
    "        log_p_k1[i] = -eta*1*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma1) - scipy.special.gammaln((i+1)*gamma1 + \n",
    "                  list(data[(q-1):(len(data)-1)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "    log_p_k1_new = log_p_k1[log_p_k1 != 0] - np.max(log_p_k1[log_p_k1 != 0])\n",
    "    act_p_k1 = np.exp(log_p_k1_new)\n",
    "    act_p1 = act_p_k1/np.sum(act_p_k1)\n",
    "    p1 = np.append(np.zeros(max(z_j_t[0, :, s+1])-1), act_p1)\n",
    "    k1[s+1] = np.random.choice(np.arange(1, C0+1), p = p1)\n",
    "\n",
    "    log_p_k2 = np.zeros(C0)\n",
    "    for i in np.arange(max(z_j_t[1, :, s+1])-1, C0):\n",
    "        log_p_k2[i] = -eta*2*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma2) - scipy.special.gammaln((i+1)*gamma2 + \n",
    "                  list(data[(q-2):(len(data)-2)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "    log_p_k2_new = log_p_k2[log_p_k2 != 0] - np.max(log_p_k2[log_p_k2 != 0])\n",
    "    act_p_k2 = np.exp(log_p_k2_new)\n",
    "    act_p2 = act_p_k2/np.sum(act_p_k2)\n",
    "    p2 = np.append(np.zeros(max(z_j_t[1, :, s+1])-1), act_p2)\n",
    "    k2[s+1] = np.random.choice(np.arange(1, C0+1), p = p2)\n",
    "\n",
    "    log_p_k3 = np.zeros(C0)\n",
    "    for i in np.arange(max(z_j_t[2, :, s+1])-1, C0):\n",
    "        log_p_k3[i] = -eta*3*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma3) - scipy.special.gammaln((i+1)*gamma3 + \n",
    "                  list(data[(q-3):(len(data)-3)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "    log_p_k3_new = log_p_k3[log_p_k3 != 0] - np.max(log_p_k3[log_p_k3 != 0])\n",
    "    act_p_k3 = np.exp(log_p_k3_new)\n",
    "    act_p3 = act_p_k3/np.sum(act_p_k3)\n",
    "    p3 = np.append(np.zeros(max(z_j_t[2, :, s+1])-1), act_p3)\n",
    "    k3[s+1] = np.random.choice(range(1, C0+1), p = p3)\n",
    "\n",
    "    log_p_k4 = np.zeros(C0)\n",
    "    for i in np.arange(max(z_j_t[3, :, s+1])-1, C0):\n",
    "        log_p_k4[i] = -eta*4*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma4) - scipy.special.gammaln((i+1)*gamma4 + \n",
    "                  list(data[(q-4):(len(data)-4)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "    log_p_k4_new = log_p_k4[log_p_k4 != 0] - np.max(log_p_k4[log_p_k4 != 0])\n",
    "    act_p_k4 = np.exp(log_p_k4_new)\n",
    "    act_p4 = act_p_k4/np.sum(act_p_k4)\n",
    "    p4 = np.append(np.zeros(max(z_j_t[3, :, s+1])-1), act_p4)\n",
    "    k4[s+1] = np.random.choice(range(1, C0+1), p = p4)\n",
    "\n",
    "    log_p_k5 = np.zeros(C0)\n",
    "    for i in np.arange(max(z_j_t[4, :, s+1])-1, C0):\n",
    "        log_p_k5[i] = -eta*5*(i+1) + np.sum([scipy.special.gammaln((i+1)*gamma5) - scipy.special.gammaln((i+1)*gamma5 + \n",
    "                  list(data[(q-5):(len(data)-5)]).count(r)) for r in np.arange(1, C0+1)])\n",
    "    log_p_k5_new = log_p_k5[log_p_k5 != 0] - np.max(log_p_k5[log_p_k5 != 0])\n",
    "    act_p_k5 = np.exp(log_p_k5_new)\n",
    "    act_p5 = act_p_k5/np.sum(act_p_k5)\n",
    "    p5 = np.append(np.zeros(max(z_j_t[4, :, s+1])-1), act_p5)\n",
    "    k5[s+1] = np.random.choice(range(1, C0+1), p = p5)\n",
    "    \n",
    "    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]],\n",
       "\n",
       "\n",
       "         [[[ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085],\n",
       "           [ 0.91276127,  0.02971788,  0.05752085]],\n",
       "\n",
       "          [[ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744],\n",
       "           [ 0.41662366,  0.2524589 ,  0.33091744]],\n",
       "\n",
       "          [[ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095],\n",
       "           [ 0.37775019,  0.20962886,  0.41262095]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]],\n",
       "\n",
       "\n",
       "         [[[ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097],\n",
       "           [ 0.30831249,  0.01163654,  0.68005097]],\n",
       "\n",
       "          [[ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281],\n",
       "           [ 0.07734717,  0.90913003,  0.01352281]],\n",
       "\n",
       "          [[ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362],\n",
       "           [ 0.42026617,  0.23610021,  0.34363362]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]],\n",
       "\n",
       "\n",
       "         [[[ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662],\n",
       "           [ 0.43437864,  0.15847474,  0.40714662]],\n",
       "\n",
       "          [[ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286],\n",
       "           [ 0.32935605,  0.42012109,  0.25052286]],\n",
       "\n",
       "          [[ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245],\n",
       "           [ 0.15357667,  0.08399088,  0.76243245]]]]]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 2, 1, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1,\n",
       "       2, 2, 3, 2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3,\n",
       "       2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3,\n",
       "       2, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 3,\n",
       "       3, 3, 3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3,\n",
       "       3, 3, 1, 1, 1, 3, 2, 1, 1, 2, 2, 3, 1, 1, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEhCAYAAAAqDTTQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123704ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.hist(k1[10000:])\n",
    "plt.title('k1')\n",
    "\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.hist(k2[10000:])\n",
    "plt.title('k2')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.hist(k3[10000:])\n",
    "plt.title('k3')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.hist(k4[10000:])\n",
    "plt.title('k4')\n",
    "\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.hist(k5[10000:])\n",
    "plt.title('k5')\n",
    "\n",
    "plt.gca().yaxis.set_minor_formatter(NullFormatter())\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.5,\n",
    "                    wspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[[ 0.88276098,  0.0406489 ,  0.07659011],\n",
       "           [ 0.88276098,  0.0406489 ,  0.07659011],\n",
       "           [ 0.88276098,  0.0406489 ,  0.07659011]],\n",
       "\n",
       "          [[ 0.38209395,  0.2745917 ,  0.34331435],\n",
       "           [ 0.38209395,  0.2745917 ,  0.34331435],\n",
       "           [ 0.38209395,  0.2745917 ,  0.34331435]],\n",
       "\n",
       "          [[ 0.3653482 ,  0.2610028 ,  0.373649  ],\n",
       "           [ 0.3653482 ,  0.2610028 ,  0.373649  ],\n",
       "           [ 0.3653482 ,  0.2610028 ,  0.373649  ]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88261127,  0.04068498,  0.07670374],\n",
       "           [ 0.88261127,  0.04068498,  0.07670374],\n",
       "           [ 0.88261127,  0.04068498,  0.07670374]],\n",
       "\n",
       "          [[ 0.38209651,  0.27464375,  0.34325974],\n",
       "           [ 0.38209651,  0.27464375,  0.34325974],\n",
       "           [ 0.38209651,  0.27464375,  0.34325974]],\n",
       "\n",
       "          [[ 0.36539596,  0.26103513,  0.37356891],\n",
       "           [ 0.36539596,  0.26103513,  0.37356891],\n",
       "           [ 0.36539596,  0.26103513,  0.37356891]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88255976,  0.04072663,  0.07671361],\n",
       "           [ 0.88255976,  0.04072663,  0.07671361],\n",
       "           [ 0.88255976,  0.04072663,  0.07671361]],\n",
       "\n",
       "          [[ 0.38206771,  0.27471035,  0.34322194],\n",
       "           [ 0.38206771,  0.27471035,  0.34322194],\n",
       "           [ 0.38206771,  0.27471035,  0.34322194]],\n",
       "\n",
       "          [[ 0.36540147,  0.26106401,  0.37353452],\n",
       "           [ 0.36540147,  0.26106401,  0.37353452],\n",
       "           [ 0.36540147,  0.26106401,  0.37353452]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.88272574,  0.04067826,  0.076596  ],\n",
       "           [ 0.88272574,  0.04067826,  0.076596  ],\n",
       "           [ 0.88272574,  0.04067826,  0.076596  ]],\n",
       "\n",
       "          [[ 0.38209315,  0.2745969 ,  0.34330995],\n",
       "           [ 0.38209315,  0.2745969 ,  0.34330995],\n",
       "           [ 0.38209315,  0.2745969 ,  0.34330995]],\n",
       "\n",
       "          [[ 0.36533857,  0.26102687,  0.37363457],\n",
       "           [ 0.36533857,  0.26102687,  0.37363457],\n",
       "           [ 0.36533857,  0.26102687,  0.37363457]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88257603,  0.04071434,  0.07670963],\n",
       "           [ 0.88257603,  0.04071434,  0.07670963],\n",
       "           [ 0.88257603,  0.04071434,  0.07670963]],\n",
       "\n",
       "          [[ 0.38209571,  0.27464895,  0.34325534],\n",
       "           [ 0.38209571,  0.27464895,  0.34325534],\n",
       "           [ 0.38209571,  0.27464895,  0.34325534]],\n",
       "\n",
       "          [[ 0.36538632,  0.2610592 ,  0.37355448],\n",
       "           [ 0.36538632,  0.2610592 ,  0.37355448],\n",
       "           [ 0.36538632,  0.2610592 ,  0.37355448]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88252452,  0.04075598,  0.0767195 ],\n",
       "           [ 0.88252452,  0.04075598,  0.0767195 ],\n",
       "           [ 0.88252452,  0.04075598,  0.0767195 ]],\n",
       "\n",
       "          [[ 0.38206691,  0.27471555,  0.34321754],\n",
       "           [ 0.38206691,  0.27471555,  0.34321754],\n",
       "           [ 0.38206691,  0.27471555,  0.34321754]],\n",
       "\n",
       "          [[ 0.36539183,  0.26108808,  0.37352009],\n",
       "           [ 0.36539183,  0.26108808,  0.37352009],\n",
       "           [ 0.36539183,  0.26108808,  0.37352009]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.88278659,  0.04064705,  0.07656636],\n",
       "           [ 0.88278659,  0.04064705,  0.07656636],\n",
       "           [ 0.88278659,  0.04064705,  0.07656636]],\n",
       "\n",
       "          [[ 0.38208697,  0.27458762,  0.34332541],\n",
       "           [ 0.38208697,  0.27458762,  0.34332541],\n",
       "           [ 0.38208697,  0.27458762,  0.34332541]],\n",
       "\n",
       "          [[ 0.36534726,  0.26100405,  0.37364869],\n",
       "           [ 0.36534726,  0.26100405,  0.37364869],\n",
       "           [ 0.36534726,  0.26100405,  0.37364869]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88263688,  0.04068313,  0.07667999],\n",
       "           [ 0.88263688,  0.04068313,  0.07667999],\n",
       "           [ 0.88263688,  0.04068313,  0.07667999]],\n",
       "\n",
       "          [[ 0.38208953,  0.27463967,  0.3432708 ],\n",
       "           [ 0.38208953,  0.27463967,  0.3432708 ],\n",
       "           [ 0.38208953,  0.27463967,  0.3432708 ]],\n",
       "\n",
       "          [[ 0.36539502,  0.26103638,  0.3735686 ],\n",
       "           [ 0.36539502,  0.26103638,  0.3735686 ],\n",
       "           [ 0.36539502,  0.26103638,  0.3735686 ]]],\n",
       "\n",
       "\n",
       "         [[[ 0.88258537,  0.04072477,  0.07668986],\n",
       "           [ 0.88258537,  0.04072477,  0.07668986],\n",
       "           [ 0.88258537,  0.04072477,  0.07668986]],\n",
       "\n",
       "          [[ 0.38206073,  0.27470627,  0.343233  ],\n",
       "           [ 0.38206073,  0.27470627,  0.343233  ],\n",
       "           [ 0.38206073,  0.27470627,  0.343233  ]],\n",
       "\n",
       "          [[ 0.36540053,  0.26106526,  0.37353421],\n",
       "           [ 0.36540053,  0.26106526,  0.37353421],\n",
       "           [ 0.36540053,  0.26106526,  0.37353421]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[ 0.38050385,  0.18710936,  0.43238679],\n",
       "           [ 0.38050385,  0.18710936,  0.43238679],\n",
       "           [ 0.38050385,  0.18710936,  0.43238679]],\n",
       "\n",
       "          [[ 0.06690513,  0.82754491,  0.10554996],\n",
       "           [ 0.06690513,  0.82754491,  0.10554996],\n",
       "           [ 0.06690513,  0.82754491,  0.10554996]],\n",
       "\n",
       "          [[ 0.32687427,  0.29909546,  0.37403027],\n",
       "           [ 0.32687427,  0.29909546,  0.37403027],\n",
       "           [ 0.32687427,  0.29909546,  0.37403027]]],\n",
       "\n",
       "\n",
       "         [[[ 0.3804742 ,  0.18716343,  0.43236237],\n",
       "           [ 0.3804742 ,  0.18716343,  0.43236237],\n",
       "           [ 0.3804742 ,  0.18716343,  0.43236237]],\n",
       "\n",
       "          [[ 0.06685903,  0.82752159,  0.10561938],\n",
       "           [ 0.06685903,  0.82752159,  0.10561938],\n",
       "           [ 0.06685903,  0.82752159,  0.10561938]],\n",
       "\n",
       "          [[ 0.32683381,  0.29915744,  0.37400875],\n",
       "           [ 0.32683381,  0.29915744,  0.37400875],\n",
       "           [ 0.32683381,  0.29915744,  0.37400875]]],\n",
       "\n",
       "\n",
       "         [[[ 0.38050489,  0.18713384,  0.43236127],\n",
       "           [ 0.38050489,  0.18713384,  0.43236127],\n",
       "           [ 0.38050489,  0.18713384,  0.43236127]],\n",
       "\n",
       "          [[ 0.06691553,  0.82748064,  0.10560383],\n",
       "           [ 0.06691553,  0.82748064,  0.10560383],\n",
       "           [ 0.06691553,  0.82748064,  0.10560383]],\n",
       "\n",
       "          [[ 0.32692112,  0.29910434,  0.37397454],\n",
       "           [ 0.32692112,  0.29910434,  0.37397454],\n",
       "           [ 0.32692112,  0.29910434,  0.37397454]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.38049394,  0.18713647,  0.43236959],\n",
       "           [ 0.38049394,  0.18713647,  0.43236959],\n",
       "           [ 0.38049394,  0.18713647,  0.43236959]],\n",
       "\n",
       "          [[ 0.06692121,  0.82750678,  0.10557201],\n",
       "           [ 0.06692121,  0.82750678,  0.10557201],\n",
       "           [ 0.06692121,  0.82750678,  0.10557201]],\n",
       "\n",
       "          [[ 0.32687455,  0.29910959,  0.37401586],\n",
       "           [ 0.32687455,  0.29910959,  0.37401586],\n",
       "           [ 0.32687455,  0.29910959,  0.37401586]]],\n",
       "\n",
       "\n",
       "         [[[ 0.38046428,  0.18719054,  0.43234518],\n",
       "           [ 0.38046428,  0.18719054,  0.43234518],\n",
       "           [ 0.38046428,  0.18719054,  0.43234518]],\n",
       "\n",
       "          [[ 0.06687511,  0.82748345,  0.10564143],\n",
       "           [ 0.06687511,  0.82748345,  0.10564143],\n",
       "           [ 0.06687511,  0.82748345,  0.10564143]],\n",
       "\n",
       "          [[ 0.3268341 ,  0.29917157,  0.37399433],\n",
       "           [ 0.3268341 ,  0.29917157,  0.37399433],\n",
       "           [ 0.3268341 ,  0.29917157,  0.37399433]]],\n",
       "\n",
       "\n",
       "         [[[ 0.38049497,  0.18716095,  0.43234407],\n",
       "           [ 0.38049497,  0.18716095,  0.43234407],\n",
       "           [ 0.38049497,  0.18716095,  0.43234407]],\n",
       "\n",
       "          [[ 0.06693161,  0.82744251,  0.10562588],\n",
       "           [ 0.06693161,  0.82744251,  0.10562588],\n",
       "           [ 0.06693161,  0.82744251,  0.10562588]],\n",
       "\n",
       "          [[ 0.3269214 ,  0.29911847,  0.37396013],\n",
       "           [ 0.3269214 ,  0.29911847,  0.37396013],\n",
       "           [ 0.3269214 ,  0.29911847,  0.37396013]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.3805124 ,  0.18710952,  0.43237808],\n",
       "           [ 0.3805124 ,  0.18710952,  0.43237808],\n",
       "           [ 0.3805124 ,  0.18710952,  0.43237808]],\n",
       "\n",
       "          [[ 0.06690686,  0.82754116,  0.10555198],\n",
       "           [ 0.06690686,  0.82754116,  0.10555198],\n",
       "           [ 0.06690686,  0.82754116,  0.10555198]],\n",
       "\n",
       "          [[ 0.32687411,  0.2990997 ,  0.37402619],\n",
       "           [ 0.32687411,  0.2990997 ,  0.37402619],\n",
       "           [ 0.32687411,  0.2990997 ,  0.37402619]]],\n",
       "\n",
       "\n",
       "         [[[ 0.38048274,  0.18716359,  0.43235366],\n",
       "           [ 0.38048274,  0.18716359,  0.43235366],\n",
       "           [ 0.38048274,  0.18716359,  0.43235366]],\n",
       "\n",
       "          [[ 0.06686076,  0.82751784,  0.1056214 ],\n",
       "           [ 0.06686076,  0.82751784,  0.1056214 ],\n",
       "           [ 0.06686076,  0.82751784,  0.1056214 ]],\n",
       "\n",
       "          [[ 0.32683366,  0.29916168,  0.37400466],\n",
       "           [ 0.32683366,  0.29916168,  0.37400466],\n",
       "           [ 0.32683366,  0.29916168,  0.37400466]]],\n",
       "\n",
       "\n",
       "         [[[ 0.38051343,  0.18713401,  0.43235256],\n",
       "           [ 0.38051343,  0.18713401,  0.43235256],\n",
       "           [ 0.38051343,  0.18713401,  0.43235256]],\n",
       "\n",
       "          [[ 0.06691725,  0.82747689,  0.10560586],\n",
       "           [ 0.06691725,  0.82747689,  0.10560586],\n",
       "           [ 0.06691725,  0.82747689,  0.10560586]],\n",
       "\n",
       "          [[ 0.32692096,  0.29910858,  0.37397046],\n",
       "           [ 0.32692096,  0.29910858,  0.37397046],\n",
       "           [ 0.32692096,  0.29910858,  0.37397046]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[ 0.36254933,  0.2627605 ,  0.37469016],\n",
       "           [ 0.36254933,  0.2627605 ,  0.37469016],\n",
       "           [ 0.36254933,  0.2627605 ,  0.37469016]],\n",
       "\n",
       "          [[ 0.33632684,  0.31018552,  0.35348764],\n",
       "           [ 0.33632684,  0.31018552,  0.35348764],\n",
       "           [ 0.33632684,  0.31018552,  0.35348764]],\n",
       "\n",
       "          [[ 0.13305898,  0.13485466,  0.73208636],\n",
       "           [ 0.13305898,  0.13485466,  0.73208636],\n",
       "           [ 0.13305898,  0.13485466,  0.73208636]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36247727,  0.26280292,  0.37471981],\n",
       "           [ 0.36247727,  0.26280292,  0.37471981],\n",
       "           [ 0.36247727,  0.26280292,  0.37471981]],\n",
       "\n",
       "          [[ 0.33621784,  0.31022199,  0.35356016],\n",
       "           [ 0.33621784,  0.31022199,  0.35356016],\n",
       "           [ 0.33621784,  0.31022199,  0.35356016]],\n",
       "\n",
       "          [[ 0.13309404,  0.13485846,  0.7320475 ],\n",
       "           [ 0.13309404,  0.13485846,  0.7320475 ],\n",
       "           [ 0.13309404,  0.13485846,  0.7320475 ]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36250856,  0.26280971,  0.37468174],\n",
       "           [ 0.36250856,  0.26280971,  0.37468174],\n",
       "           [ 0.36250856,  0.26280971,  0.37468174]],\n",
       "\n",
       "          [[ 0.33629923,  0.31017596,  0.35352482],\n",
       "           [ 0.33629923,  0.31017596,  0.35352482],\n",
       "           [ 0.33629923,  0.31017596,  0.35352482]],\n",
       "\n",
       "          [[ 0.13310252,  0.13488518,  0.7320123 ],\n",
       "           [ 0.13310252,  0.13488518,  0.7320123 ],\n",
       "           [ 0.13310252,  0.13488518,  0.7320123 ]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.36254978,  0.26276213,  0.37468809],\n",
       "           [ 0.36254978,  0.26276213,  0.37468809],\n",
       "           [ 0.36254978,  0.26276213,  0.37468809]],\n",
       "\n",
       "          [[ 0.33631836,  0.31018266,  0.35349898],\n",
       "           [ 0.33631836,  0.31018266,  0.35349898],\n",
       "           [ 0.33631836,  0.31018266,  0.35349898]],\n",
       "\n",
       "          [[ 0.13306644,  0.13487726,  0.7320563 ],\n",
       "           [ 0.13306644,  0.13487726,  0.7320563 ],\n",
       "           [ 0.13306644,  0.13487726,  0.7320563 ]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36247772,  0.26280455,  0.37471773],\n",
       "           [ 0.36247772,  0.26280455,  0.37471773],\n",
       "           [ 0.36247772,  0.26280455,  0.37471773]],\n",
       "\n",
       "          [[ 0.33620935,  0.31021914,  0.35357151],\n",
       "           [ 0.33620935,  0.31021914,  0.35357151],\n",
       "           [ 0.33620935,  0.31021914,  0.35357151]],\n",
       "\n",
       "          [[ 0.1331015 ,  0.13488106,  0.73201745],\n",
       "           [ 0.1331015 ,  0.13488106,  0.73201745],\n",
       "           [ 0.1331015 ,  0.13488106,  0.73201745]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36250901,  0.26281133,  0.37467966],\n",
       "           [ 0.36250901,  0.26281133,  0.37467966],\n",
       "           [ 0.36250901,  0.26281133,  0.37467966]],\n",
       "\n",
       "          [[ 0.33629074,  0.3101731 ,  0.35353616],\n",
       "           [ 0.33629074,  0.3101731 ,  0.35353616],\n",
       "           [ 0.33629074,  0.3101731 ,  0.35353616]],\n",
       "\n",
       "          [[ 0.13310998,  0.13490777,  0.73198225],\n",
       "           [ 0.13310998,  0.13490777,  0.73198225],\n",
       "           [ 0.13310998,  0.13490777,  0.73198225]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.36255202,  0.26274956,  0.37469842],\n",
       "           [ 0.36255202,  0.26274956,  0.37469842],\n",
       "           [ 0.36255202,  0.26274956,  0.37469842]],\n",
       "\n",
       "          [[ 0.336327  ,  0.31016974,  0.35350326],\n",
       "           [ 0.336327  ,  0.31016974,  0.35350326],\n",
       "           [ 0.336327  ,  0.31016974,  0.35350326]],\n",
       "\n",
       "          [[ 0.13305687,  0.13485996,  0.73208316],\n",
       "           [ 0.13305687,  0.13485996,  0.73208316],\n",
       "           [ 0.13305687,  0.13485996,  0.73208316]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36247996,  0.26279198,  0.37472806],\n",
       "           [ 0.36247996,  0.26279198,  0.37472806],\n",
       "           [ 0.36247996,  0.26279198,  0.37472806]],\n",
       "\n",
       "          [[ 0.336218  ,  0.31020622,  0.35357578],\n",
       "           [ 0.336218  ,  0.31020622,  0.35357578],\n",
       "           [ 0.336218  ,  0.31020622,  0.35357578]],\n",
       "\n",
       "          [[ 0.13309193,  0.13486376,  0.73204431],\n",
       "           [ 0.13309193,  0.13486376,  0.73204431],\n",
       "           [ 0.13309193,  0.13486376,  0.73204431]]],\n",
       "\n",
       "\n",
       "         [[[ 0.36251125,  0.26279876,  0.37468999],\n",
       "           [ 0.36251125,  0.26279876,  0.37468999],\n",
       "           [ 0.36251125,  0.26279876,  0.37468999]],\n",
       "\n",
       "          [[ 0.33629939,  0.31016018,  0.35354044],\n",
       "           [ 0.33629939,  0.31016018,  0.35354044],\n",
       "           [ 0.33629939,  0.31016018,  0.35354044]],\n",
       "\n",
       "          [[ 0.13310042,  0.13489048,  0.73200911],\n",
       "           [ 0.13310042,  0.13489048,  0.73200911],\n",
       "           [ 0.13310042,  0.13489048,  0.73200911]]]]]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_den = np.mean(rec_pred_y_den, axis = 6)\n",
    "pred_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32687427,  0.29909546,  0.37403027])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_den[1,0,0,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Allain/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  3.,  3.,  1.,  2.,  1.,  3.,  3.,  1.,  1.,  2.,  1.,\n",
       "        1.,  2.,  2.,  2.,  1.,  1.,  3.,  3.,  2.,  2.,  2.,  3.,  3.,\n",
       "        3.,  3.,  3.,  2.,  3.,  2.,  2.,  2.,  3.,  2.,  3.,  2.,  2.,\n",
       "        2.,  2.,  3.,  3.,  3.,  3.,  2.,  3.,  2.,  1.,  2.,  1.,  1.,\n",
       "        1.,  3.,  1.,  3.,  1.,  1.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,\n",
       "        2.,  1.,  1.,  3.,  3.,  1.,  1.,  2.,  1.,  3.,  2.,  3.,  3.,\n",
       "        3.,  2.,  3.,  3.,  3.,  1.,  2.,  1.,  1.,  2.,  1.,  2.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  3.,  2.,  3.,  2.,\n",
       "        1.,  1.,  1.,  3.,  2.,  2.,  3.,  2.,  2.,  1.,  3.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  2.,  3.,  3.,  2.,  2.,  3.,  2.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  1.,  3.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,\n",
       "        2.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  1.,  1.,  1.,  1.,\n",
       "        3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  2.,  1.,  3.,  3.,\n",
       "        3.,  1.,  3.,  3.,  2.,  2.,  2.,  3.,  2.,  1.,  2.,  3.,  1.,\n",
       "        3.,  1.,  3.,  3.,  3.,  2.,  3.,  2.,  2.,  3.,  3.,  1.,  3.,\n",
       "        3.,  2.,  3.,  3.,  1.,  2.,  2.,  1.,  2.,  1.,  1.,  1.,  2.,\n",
       "        2.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,  3.,  3.,  3.,\n",
       "        1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  3.,\n",
       "        3.,  1.,  2.,  2.,  1.,  2.,  3.,  2.,  2.,  3.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  3.,  3.,  2.,  1.,  3.,  3.,  2.,  3.,  3.,  2.,\n",
       "        2.,  3.,  3.,  2.,  2.,  3.,  2.,  1.,  1.,  2.,  3.,  2.,  1.,\n",
       "        2.,  2.,  1.,  2.,  2.,  1.,  1.,  3.,  1.,  3.,  3.,  3.,  3.,\n",
       "        3.,  2.,  3.,  1.,  3.,  1.,  3.,  1.,  3.,  3.,  2.,  2.,  1.,\n",
       "        3.,  1.,  1.,  1.,  3.,  3.,  1.,  1.,  3.,  3.,  2.,  2.,  3.,\n",
       "        1.,  3.,  3.,  3.,  2.,  3.,  1.,  1.,  2.,  1.,  1.,  3.,  3.,\n",
       "        1.,  1.,  3.,  2.,  1.,  2.,  3.,  3.,  3.,  2.,  3.,  2.,  3.,\n",
       "        2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,  1.,\n",
       "        3.,  1.,  1.,  2.,  2.,  2.,  3.,  2.,  2.,  3.,  3.,  2.,  2.,\n",
       "        2.,  3.,  3.,  1.,  2.,  3.,  2.,  1.,  3.,  3.,  1.,  2.,  1.,\n",
       "        1.,  1.,  1.,  3.,  1.,  1.,  3.,  3.,  3.,  2.,  1.,  3.,  1.,\n",
       "        2.,  3.,  3.,  3.,  1.,  2.,  2.,  2.,  2.,  3.,  3.,  1.,  3.,\n",
       "        1.,  1.,  3.,  2.,  1.,  3.,  1.,  3.,  2.,  3.,  1.,  2.,  1.,\n",
       "        1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,\n",
       "        3.,  1.,  2.,  3.,  2.,  3.,  3.,  1.,  1.,  2.,  1.,  1.,  2.,\n",
       "        1.,  3.,  2.,  1.,  2.,  1.,  2.,  3.,  2.,  3.,  3.,  3.,  3.,\n",
       "        3.,  1.,  3.,  3.,  3.,  3.,  1.,  3.,  3.,  3.,  3.,  3.,  2.,\n",
       "        3.,  3.,  1.,  3.,  1.,  3.,  2.,  3.,  1.,  3.,  3.,  3.,  3.,\n",
       "        1.,  2.,  3.,  2.,  3.,  1.])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## generate predictive data\n",
    "pred_data = np.zeros(len(data_all) - len(data))\n",
    "for i in np.arange(len(data),len(data_all)):\n",
    "    yt1 = data_all[i-1]\n",
    "    yt2 = data_all[i-2]\n",
    "    yt3 = data_all[i-3]\n",
    "    yt4 = data_all[i-4]\n",
    "    yt5 = data_all[i-5]\n",
    "    prob = pred_den[yt1-1, yt2-1, yt3-1, yt4-1, yt5-1]\n",
    "    pred_data[i - len(data)] = np.random.choice(np.arange(1, C0+1), p = prob)\n",
    "\n",
    "prob_pred_data = np.zeros((len(data_all) - len(data), C0))    \n",
    "pred_data_fix = np.append(data[-5:], pred_data)\n",
    "for i in np.arange(5, len(pred_data_fix)):\n",
    "        yt1 = pred_data_fix[i-1]\n",
    "        yt2 = pred_data_fix[i-2]\n",
    "        yt3 = pred_data_fix[i-3]\n",
    "        yt4 = pred_data_fix[i-4]\n",
    "        yt5 = pred_data_fix[i-5]\n",
    "        prob_pred_data[i-5,:] = pred_y_den[yt1-1, yt2-1, yt3-1, yt4-1, yt5-1]\n",
    "prob_pred_data\n",
    "\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00671526,  0.97635037,  0.01693437])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 1, 2, 1, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1,\n",
       "       2, 2, 3, 2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3,\n",
       "       2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3,\n",
       "       2, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 3,\n",
       "       3, 3, 3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3,\n",
       "       3, 3, 1, 1, 1, 3, 2, 1, 1, 2, 2, 3, 1, 1, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  2.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  2.,  1.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  3.,  1.,  3.,  1.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  2.,  3.,  1.,  1.,  3.,  1.,  3.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  2.,  3.,  2.,  1.,\n",
       "        3.,  1.,  1.,  3.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  3.,  3.,  1.,  3.,  3.,  1.,  3.,  1.,  3.,  3.,  3.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  3.,  3.,\n",
       "        1.,  1.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  2.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  2.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,\n",
       "        1.,  2.,  3.,  2.,  2.,  3.,  3.,  1.,  2.,  1.,  2.,  3.,  3.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  2.,  3.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  3.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  2.,  2.,  3.,  1.,  2.,  1.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        3.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  3.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  1.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        3.,  2.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,  2.,\n",
       "        2.,  2.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  3.,  1.,  2.,  1.,  1.,  2.,  3.,  1.,  2.,  1.,  1.,  2.,\n",
       "        1.,  1.,  2.,  1.,  1.,  2.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99 ,  0.005,  0.005],\n",
       "       [ 0.005,  0.99 ,  0.005],\n",
       "       [ 0.005,  0.005,  0.99 ],\n",
       "       ..., \n",
       "       [ 0.99 ,  0.005,  0.005],\n",
       "       [ 0.99 ,  0.005,  0.005],\n",
       "       [ 0.005,  0.99 ,  0.005]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_ori_data = np.zeros((len(data_all) - len(data), C0))\n",
    "ori_com_data = data_all[200:]\n",
    "ori_com_data = np.append(data[-5:], ori_com_data)\n",
    "ori_com_data.shape\n",
    "for i in np.arange(5, len(ori_com_data)):\n",
    "    if ori_com_data[i-3] == 1:\n",
    "        prob_ori_data[i-5:,] = np.array((0.99, 0.005, 0.005))\n",
    "    if ori_com_data[i-3] == 2:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.99, 0.005))\n",
    "    if ori_com_data[i-3] == 3:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.005, 0.99))\n",
    "prob_ori_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99 ,  0.005,  0.005],\n",
       "       [ 0.99 ,  0.005,  0.005],\n",
       "       [ 0.99 ,  0.005,  0.005],\n",
       "       ..., \n",
       "       [ 0.005,  0.99 ,  0.005],\n",
       "       [ 0.005,  0.99 ,  0.005],\n",
       "       [ 0.005,  0.99 ,  0.005]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_ori_data = np.zeros((len(data_all) - len(data), C0))\n",
    "ori_com_data = data_all[200:]\n",
    "ori_com_data = np.append(data[-5:], ori_com_data)\n",
    "for i in np.arange(5, len(ori_com_data)):\n",
    "    prob_ori_data[i-5:,] = np.array((1/3, 1/3, 1/3))\n",
    "    if ori_com_data[i-5] == 1 and ori_com_data[i-3] == 1 and ori_com_data[i-1] == 1:\n",
    "        prob_ori_data[i-5:,] = np.array((0.99, 0.005, 0.005))\n",
    "    if ori_com_data[i-5] == 2 and ori_com_data[i-3] == 2 and ori_com_data[i-1] == 2:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.99, 0.005))\n",
    "    if ori_com_data[i-5] == 3 and ori_com_data[i-3] == 3 and ori_com_data[i-1] == 3:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.005, 0.99))\n",
    "prob_ori_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       ..., \n",
       "       [ 0.005     ,  0.005     ,  0.99      ],\n",
       "       [ 0.005     ,  0.005     ,  0.99      ],\n",
       "       [ 0.005     ,  0.005     ,  0.99      ]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Important lags 4 and 1\n",
    "prob_ori_data = np.zeros((len(data_all) - len(data), C0))\n",
    "ori_com_data = data_all[200:]\n",
    "ori_com_data = np.append(data[-5:], ori_com_data)\n",
    "for i in np.arange(5, len(ori_com_data)):\n",
    "    if ori_com_data[i-4] == 1 and ori_com_data[i-1] == 1:\n",
    "        prob_ori_data[i-5:,] = np.array((0.99, 0.005, 0.005))\n",
    "    elif ori_com_data[i-4] == 2 and ori_com_data[i-1] == 2:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.99, 0.005))\n",
    "    elif ori_com_data[i-4] == 3 and ori_com_data[i-1] == 3:\n",
    "        prob_ori_data[i-5:,] = np.array((0.005, 0.005, 0.99))\n",
    "    else: prob_ori_data[i-5:,] = np.array((1/3, 1/3, 1/3))\n",
    "prob_ori_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43437864,  0.15847474,  0.40714662],\n",
       "       [ 0.91276127,  0.02971788,  0.05752085],\n",
       "       [ 0.15357667,  0.08399088,  0.76243245],\n",
       "       ..., \n",
       "       [ 0.15357667,  0.08399088,  0.76243245],\n",
       "       [ 0.30831249,  0.01163654,  0.68005097],\n",
       "       [ 0.32935605,  0.42012109,  0.25052286]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.484135043018938"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.absolute(prob_pred_data - prob_ori_data))/(3*500)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  2.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  2.,  1.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  3.,  1.,  3.,  1.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  2.,  3.,  1.,  1.,  3.,  1.,  3.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  2.,  3.,  2.,  1.,\n",
       "        3.,  1.,  1.,  3.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  3.,  3.,  1.,  3.,  3.,  1.,  3.,  1.,  3.,  3.,  3.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  3.,  3.,\n",
       "        1.,  1.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,\n",
       "        3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  1.,  1.,  3.,  2.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  2.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,\n",
       "        1.,  2.,  3.,  2.,  2.,  3.,  3.,  1.,  2.,  1.,  2.,  3.,  3.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  2.,  3.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  3.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,\n",
       "        2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  2.,  2.,  3.,  1.,  2.,  1.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        3.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  3.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  1.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        3.,  2.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  3.,  2.,  3.,  2.,\n",
       "        2.,  2.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,\n",
       "        3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,\n",
       "        1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,  2.,  3.,  1.,\n",
       "        2.,  3.,  1.,  2.,  1.,  1.,  2.,  3.,  1.,  2.,  1.,  1.,  2.,\n",
       "        1.,  1.,  2.,  1.,  1.,  2.])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 3, 3, 1, 2, 2, 3, 1, 2, 2, 3, 2, 2, 2, 1, 1, 1, 2, 3, 3, 1,\n",
       "       3, 3, 2, 3, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 1, 2,\n",
       "       3, 3, 2, 2, 1, 3, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 2, 2, 1, 3, 3,\n",
       "       1, 1, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 3, 3, 2, 2, 1, 1, 1, 2, 3, 1, 2, 2, 3, 3, 1, 1, 1,\n",
       "       1, 1, 3, 1, 1, 1, 3, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, 2, 2, 2, 1, 1,\n",
       "       3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 2, 2, 2, 3, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3,\n",
       "       2, 2, 2, 3, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 3, 1, 1, 2, 2, 3, 1, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 1, 2, 3, 1, 1, 3, 3, 1, 1, 3, 3,\n",
       "       3, 2, 2, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 1, 3, 1, 2, 2, 3, 2,\n",
       "       2, 2, 3, 2, 2, 1, 3, 2, 2, 1, 3, 1, 3, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1,\n",
       "       1, 3, 3, 1, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 3,\n",
       "       2, 2, 3, 3, 2, 2, 1, 3, 3, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 3, 1, 2, 3, 3, 3, 2, 1, 1, 1, 3, 1, 1, 1, 2, 3, 1, 1, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 200\n",
    "yt1 = data_all[i-1]\n",
    "yt2 = data_all[i-2]\n",
    "yt3 = data_all[i-3]\n",
    "yt4 = data_all[i-4]\n",
    "yt5 = data_all[i-5]\n",
    "prob = pred_y_den[yt1-1, yt2-1, yt3-1, yt4-1, yt5-1]\n",
    "pred_data[i - len(data)] = np.random.choice(np.arange(1, C0+1), p = prob)\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "       252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "       265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "       278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "       291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "       304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "       317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "       343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "       356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "       369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "       382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "       408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "       421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "       434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "       447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "       460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
       "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
       "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
       "       603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
       "       616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
       "       629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
       "       642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654,\n",
       "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
       "       668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n",
       "       681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n",
       "       694, 695, 696, 697, 698, 699, 700])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(data),len(data_all)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3,\n",
       "       1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,\n",
       "       3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2,\n",
       "       2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3,\n",
       "       3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 2, 3, 2,\n",
       "       2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3,\n",
       "       2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2,\n",
       "       3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2,\n",
       "       2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3,\n",
       "       2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1,\n",
       "       3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2, 1, 3, 2,\n",
       "       1, 3, 2, 1, 3, 2, 1, 3, 2, 1], dtype=int8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = data_all[199]\n",
    "yt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
